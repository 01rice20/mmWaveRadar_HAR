{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.image as mpimg\n",
    "import tensorflow as tf\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "from keras.models import Sequential, Model, model_from_json\n",
    "from keras.optimizers import RMSprop,Adam,SGD\n",
    "from keras.layers import Activation, Dropout, Flatten, Dense, GlobalMaxPooling2D, Conv2D, MaxPooling2D, UpSampling2D, Input\n",
    "from keras.callbacks import CSVLogger\n",
    "from livelossplot.keras import PlotLossesCallback\n",
    "import efficientnet.keras as efn\n",
    "import h5py\n",
    "import numpy as np\n",
    "import itertools\n",
    "from keras.wrappers.scikit_learn import KerasClassifier\n",
    "from cnn_utils import *\n",
    "from tensorflow.compat.v1 import ConfigProto\n",
    "from tensorflow.compat.v1 import InteractiveSession\n",
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "np.random.seed(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1. Radars Number of training samples:  519\n",
      "1. Radars Number of test samples:  130\n",
      "2. Radars Number of training samples:  1695\n",
      "2. Radars Number of test samples:  424\n",
      "3. Radars Number of training samples:  614\n",
      "3. Radars Number of test samples:  154\n"
     ]
    }
   ],
   "source": [
    "train_path = 'Spectograms_77_24_Xethrue_128x128/77_daily.hdf5'  # file path for the created .hdf5 file\n",
    "trainset = h5py.File(train_path, \"r\")\n",
    "train_path2 = 'Spectograms_77_24_Xethrue_128x128/24_daily.hdf5'  # file path for the created .hdf5 file\n",
    "trainset2 = h5py.File(train_path2, \"r\")\n",
    "train_path3 = 'Spectograms_77_24_Xethrue_128x128/XeThru_daily.hdf5'  # file path for the created .hdf5 file\n",
    "trainset3 = h5py.File(train_path3, \"r\")\n",
    "\n",
    "# valid_path = 'Spectograms_77_24_Xethrue_128x128/77_daily.hdf5'  # file path for the created .hdf5 file\n",
    "# validset = h5py.File(valid_path, \"r\")\n",
    "# valid_path2 = 'Spectograms_77_24_Xethrue_128x128/24_daily.hdf5'  # file path for the created .hdf5 file\n",
    "# validset2 = h5py.File(valid_path2, \"r\")\n",
    "# valid_path3 = 'Spectograms_77_24_Xethrue_128x128/XeThru_daily.hdf5'  # file path for the created .hdf5 file\n",
    "# validset3 = h5py.File(valid_path3, \"r\")\n",
    "\n",
    "test_path = 'Spectograms_77_24_Xethrue_128x128/77_daily.hdf5'  # file path for the created .hdf5 file\n",
    "testset = h5py.File(test_path, \"r\")\n",
    "test_path2 = 'Spectograms_77_24_Xethrue_128x128/24_daily.hdf5'  # file path for the created .hdf5 file\n",
    "testset2 = h5py.File(test_path2, \"r\")\n",
    "test_path3 = 'Spectograms_77_24_Xethrue_128x128/XeThru_daily.hdf5'  # file path for the created .hdf5 file\n",
    "testset3 = h5py.File(test_path3, \"r\")\n",
    "\n",
    "X_train_orig = np.array(trainset[\"train_img\"])\n",
    "Y_train_orig = np.array(trainset[\"train_labels\"])\n",
    "# X_valid_orig = np.array(validset[\"valid_img\"])\n",
    "# Y_valid_orig = np.array(validset[\"valid_labels\"])\n",
    "X_test_orig = np.array(testset[\"test_img\"])\n",
    "Y_test_orig = np.array(testset[\"test_labels\"])\n",
    "print('1. Radar''s Number of training samples: ', len(Y_train_orig))\n",
    "# print('1. Radar''s Number of validation samples: ', len(X_valid_orig))\n",
    "print('1. Radar''s Number of test samples: ', len(Y_test_orig))\n",
    "\n",
    "X_train_orig2 = np.array(trainset2[\"train_img\"])\n",
    "Y_train_orig2 = np.array(trainset2[\"train_labels\"])\n",
    "# X_valid_orig2 = np.array(validset2[\"valid_img\"])\n",
    "# Y_valid_orig2 = np.array(validset2[\"valid_labels\"])\n",
    "X_test_orig2 = np.array(testset2[\"test_img\"])\n",
    "Y_test_orig2 = np.array(testset2[\"test_labels\"])\n",
    "print('2. Radar''s Number of training samples: ', len(X_train_orig2))\n",
    "# print('2. Radar''s Number of validation samples: ', len(X_valid_orig2))\n",
    "print('2. Radar''s Number of test samples: ', len(X_test_orig2))\n",
    "\n",
    "X_train_orig3 = np.array(trainset3[\"train_img\"])\n",
    "Y_train_orig3 = np.array(trainset3[\"train_labels\"])\n",
    "# X_valid_orig3 = np.array(validset3[\"valid_img\"])\n",
    "# Y_valid_orig3 = np.array(validset3[\"valid_labels\"])\n",
    "X_test_orig3 = np.array(testset3[\"test_img\"])\n",
    "Y_test_orig3 = np.array(testset3[\"test_labels\"])\n",
    "print('3. Radar''s Number of training samples: ', len(X_train_orig3))\n",
    "# print('3. Radar''s Number of validation samples: ', len(X_valid_orig3))\n",
    "print('3. Radar''s Number of test samples: ', len(X_test_orig3))\n",
    "\n",
    "trainset.close()\n",
    "# validset.close()\n",
    "testset.close()\n",
    "trainset2.close()\n",
    "# validset2.close()\n",
    "testset2.close()\n",
    "trainset3.close()\n",
    "# validset3.close()\n",
    "testset3.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Examine the shapes of data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "number of training examples = 519\n",
      "number of test examples = 130\n",
      "X_train shape: (519, 128, 128, 3)\n",
      "Y_train shape: (519, 11)\n",
      "X_test shape: (130, 128, 128, 3)\n",
      "Y_test shape: (130, 11)\n",
      "\n",
      "number of training examples = 1695\n",
      "number of test examples = 424\n",
      "X_train2 shape: (1695, 128, 128, 3)\n",
      "Y_train2 shape: (1695, 11)\n",
      "X_test2 shape: (424, 128, 128, 3)\n",
      "Y_test2 shape: (424, 11)\n",
      "\n",
      "number of training examples = 614\n",
      "number of test examples = 154\n",
      "X_train3 shape: (614, 128, 128, 3)\n",
      "Y_train3 shape: (614, 11)\n",
      "X_test3 shape: (154, 128, 128, 3)\n",
      "Y_test3 shape: (154, 11)\n"
     ]
    }
   ],
   "source": [
    "X_train = X_train_orig/255.\n",
    "# X_valid = X_valid_orig/255.\n",
    "X_test = X_test_orig/255.\n",
    "Y_train = convert_to_one_hot(Y_train_orig, 11).T\n",
    "# Y_valid = convert_to_one_hot(Y_valid_orig, 11).T\n",
    "Y_test = convert_to_one_hot(Y_test_orig, 11).T\n",
    "print (\"number of training examples = \" + str(X_train.shape[0]))\n",
    "# print (\"number of validation examples = \" + str(X_valid.shape[0]))\n",
    "print (\"number of test examples = \" + str(X_test.shape[0]))\n",
    "print (\"X_train shape: \" + str(X_train.shape))\n",
    "print (\"Y_train shape: \" + str(Y_train.shape))\n",
    "# print (\"X_valid shape: \" + str(X_valid.shape))\n",
    "# print (\"Y_valid shape: \" + str(Y_valid.shape))\n",
    "print (\"X_test shape: \" + str(X_test.shape))\n",
    "print (\"Y_test shape: \" + str(Y_test.shape))\n",
    "conv_layers = {}\n",
    "\n",
    "X_train2 = X_train_orig2/255.\n",
    "# X_valid2 = X_valid_orig2/255.\n",
    "X_test2 = X_test_orig2/255.\n",
    "Y_train2 = convert_to_one_hot(Y_train_orig2, 11).T\n",
    "# Y_valid2 = convert_to_one_hot(Y_valid_orig2, 11).T\n",
    "Y_test2 = convert_to_one_hot(Y_test_orig2, 11).T\n",
    "print (\"\\nnumber of training examples = \" + str(X_train2.shape[0]))\n",
    "# print (\"number of validation examples = \" + str(X_valid2.shape[0]))\n",
    "print (\"number of test examples = \" + str(X_test2.shape[0]))\n",
    "print (\"X_train2 shape: \" + str(X_train2.shape))\n",
    "print (\"Y_train2 shape: \" + str(Y_train2.shape))\n",
    "# print (\"X_valid2 shape: \" + str(X_valid2.shape))\n",
    "# print (\"Y_valid2 shape: \" + str(Y_valid2.shape))\n",
    "print (\"X_test2 shape: \" + str(X_test2.shape))\n",
    "print (\"Y_test2 shape: \" + str(Y_test2.shape))\n",
    "\n",
    "X_train3 = X_train_orig3/255.\n",
    "# X_valid3 = X_valid_orig3/255.\n",
    "X_test3 = X_test_orig3/255.\n",
    "Y_train3 = convert_to_one_hot(Y_train_orig3, 11).T\n",
    "# Y_valid3 = convert_to_one_hot(Y_valid_orig3, 11).T\n",
    "Y_test3 = convert_to_one_hot(Y_test_orig3, 11).T\n",
    "print (\"\\nnumber of training examples = \" + str(X_train3.shape[0]))\n",
    "# print (\"number of validation examples = \" + str(X_valid3.shape[0]))\n",
    "print (\"number of test examples = \" + str(X_test3.shape[0]))\n",
    "print (\"X_train3 shape: \" + str(X_train3.shape))\n",
    "print (\"Y_train3 shape: \" + str(Y_train3.shape))\n",
    "# print (\"X_valid3 shape: \" + str(X_valid3.shape))\n",
    "# print (\"Y_valid3 shape: \" + str(Y_valid3.shape))\n",
    "print (\"X_test3 shape: \" + str(X_test3.shape))\n",
    "print (\"Y_test3 shape: \" + str(Y_test3.shape))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Select Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# set flag: '0' for 77ghz, '1' for 24ghz, '2' for 10ghz\n",
    "flag = 0\n",
    "\n",
    "if flag==0:\n",
    "    X_train = X_train\n",
    "    Y_train = Y_train\n",
    "#     X_valid = X_valid\n",
    "#     Y_valid = Y_valid\n",
    "    X_test = X_test\n",
    "    Y_test = Y_test\n",
    "    radar = 77\n",
    "elif flag==1:\n",
    "    X_train = X_train2\n",
    "    Y_train = Y_train2\n",
    "#     X_valid = X_valid2\n",
    "#     Y_valid = Y_valid2\n",
    "    X_test = X_test2\n",
    "    Y_test = Y_test2\n",
    "    radar = 24\n",
    "elif flag==2: \n",
    "    X_train = X_train3\n",
    "    Y_train = Y_train3\n",
    "#     X_valid = X_valid3\n",
    "#     Y_valid = Y_valid3\n",
    "    X_test = X_test3\n",
    "    Y_test = Y_test3\n",
    "    radar = 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def create_model(learn_rate = 0.001):\n",
    "    model = Sequential()\n",
    "    \n",
    "    # Encoder\n",
    "    model.add = Conv2D(8, (9, 9), activation='relu', padding='same') # 128x128x16\n",
    "    model.add = Conv2D(8, (9, 9), activation='relu', padding='same')\n",
    "    model.add = MaxPooling2D(pool_size=(2, 2)) # 64x64x16\n",
    "    model.add = Conv2D(16, (3, 3), activation='relu', padding='same') # 64x64x32\n",
    "    model.add = Conv2D(16, (3, 3), activation='relu', padding='same')\n",
    "    model.add = MaxPooling2D(pool_size=(4, 4)) # 16x16x32\n",
    "    model.add = Conv2D(32, (3, 3), activation='relu', padding='same') # 16x16x64\n",
    "    model.add = Conv2D(32, (3, 3), activation='relu', padding='same')\n",
    "    model.add = MaxPooling2D(pool_size=(4, 4)) # 4x4x64  (small and thick)\n",
    "    \n",
    "    # Decoder\n",
    "    model.add = Conv2D(32, (3, 3), activation='relu', padding='same') # 16x16x32\n",
    "    model.add = Conv2D(32, (3, 3), activation='relu', padding='same')\n",
    "    model.add = UpSampling2D((4,4)) #  16x16x64\n",
    "    model.add = Conv2D(16, (3, 3), activation='relu', padding='same') # 16x16x16\n",
    "    model.add = Conv2D(16, (3, 3), activation='relu', padding='same')\n",
    "    model.add = UpSampling2D((4,4)) # 64x64x16\n",
    "    model.add = Conv2D(8, (9, 9), activation='relu', padding='same') # 64x64x16\n",
    "    model.add = Conv2D(8, (9, 9), activation='relu', padding='same')\n",
    "    model.add = UpSampling2D((2,2)) #  128x128x16\n",
    "    model.add = Conv2D(3, (3, 3), activation='sigmoid', padding='same') # 128 x 128 x 3 / Conv2D(1, (3, 3)\n",
    "    \n",
    "    optimizer = Adam(lr = learn_rate)\n",
    "    model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "    \n",
    "    return model\n",
    " "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Grid Search"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Tensor-typed variable initializers must either be wrapped in an init_scope or callable (e.g., `tf.Variable(lambda : tf.truncated_normal([10, 40]))`) when building functions. Please file a feature request if this restriction inconveniences you.",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-33-800c895ef1fc>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      8\u001b[0m \u001b[0minput_img\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mInput\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mshape\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0minChannel\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      9\u001b[0m \u001b[0mmodel\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mKerasClassifier\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mbuild_fn\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mcreate_model\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mverbose\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 10\u001b[1;33m \u001b[0mmodel\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mModel\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0minput_img\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mcreate_model\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0minput_img\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mverbose\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     11\u001b[0m \u001b[0mmodel2\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mModel\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0minput_img\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdecoder\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mencoder2\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0minput_img\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     12\u001b[0m \u001b[0mgrid\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mGridSearchCV\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mestimator\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mmodel\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mparam_grid\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mparam_grid\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mn_jobs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;33m-\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcv\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m3\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;31m# use all the cores (n_ jobs =-1), or set to 1 if err\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-30-a161ee6b5eea>\u001b[0m in \u001b[0;36mcreate_model\u001b[1;34m(learn_rate)\u001b[0m\n\u001b[0;32m     25\u001b[0m     \u001b[0mmodel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0madd\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mConv2D\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m3\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m(\u001b[0m\u001b[1;36m3\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m3\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mactivation\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m'sigmoid'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mpadding\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m'same'\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;31m# 128 x 128 x 3 / Conv2D(1, (3, 3)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     26\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 27\u001b[1;33m     \u001b[0moptimizer\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mAdam\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mlr\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mlearn_rate\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     28\u001b[0m     \u001b[0mmodel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcompile\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mloss\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m'categorical_crossentropy'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0moptimizer\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m'adam'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmetrics\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'accuracy'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     29\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\Continuum\\anaconda3\\envs\\env\\lib\\site-packages\\keras\\optimizers.py\u001b[0m in \u001b[0;36m__init__\u001b[1;34m(self, learning_rate, beta_1, beta_2, amsgrad, **kwargs)\u001b[0m\n\u001b[0;32m    493\u001b[0m         \u001b[1;32mwith\u001b[0m \u001b[0mK\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mname_scope\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m__class__\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m__name__\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    494\u001b[0m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0miterations\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mK\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mvariable\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m'int64'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mname\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m'iterations'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 495\u001b[1;33m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mlearning_rate\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mK\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mvariable\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mlearning_rate\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mname\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m'learning_rate'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    496\u001b[0m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mbeta_1\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mK\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mvariable\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mbeta_1\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mname\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m'beta_1'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    497\u001b[0m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mbeta_2\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mK\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mvariable\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mbeta_2\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mname\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m'beta_2'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\Continuum\\anaconda3\\envs\\env\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py\u001b[0m in \u001b[0;36mvariable\u001b[1;34m(value, dtype, name, constraint)\u001b[0m\n\u001b[0;32m    618\u001b[0m     \"\"\"\n\u001b[0;32m    619\u001b[0m     v = tf_keras_backend.variable(\n\u001b[1;32m--> 620\u001b[1;33m         value, dtype=dtype, name=name, constraint=constraint)\n\u001b[0m\u001b[0;32m    621\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mhasattr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mvalue\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'tocoo'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    622\u001b[0m         \u001b[0mv\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_keras_shape\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mvalue\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtocoo\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\Continuum\\anaconda3\\envs\\env\\lib\\site-packages\\tensorflow_core\\python\\keras\\backend.py\u001b[0m in \u001b[0;36mvariable\u001b[1;34m(value, dtype, name, constraint)\u001b[0m\n\u001b[0;32m    809\u001b[0m       \u001b[0mdtype\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mdtypes_module\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mas_dtype\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdtype\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    810\u001b[0m       \u001b[0mname\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mname\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 811\u001b[1;33m       constraint=constraint)\n\u001b[0m\u001b[0;32m    812\u001b[0m   \u001b[1;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mvalue\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mndarray\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    813\u001b[0m     \u001b[0mv\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_keras_shape\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mvalue\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\Continuum\\anaconda3\\envs\\env\\lib\\site-packages\\tensorflow_core\\python\\ops\\variables.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(cls, *args, **kwargs)\u001b[0m\n\u001b[0;32m    258\u001b[0m       \u001b[1;32mreturn\u001b[0m \u001b[0mcls\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_variable_v1_call\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    259\u001b[0m     \u001b[1;32melif\u001b[0m \u001b[0mcls\u001b[0m \u001b[1;32mis\u001b[0m \u001b[0mVariable\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 260\u001b[1;33m       \u001b[1;32mreturn\u001b[0m \u001b[0mcls\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_variable_v2_call\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    261\u001b[0m     \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    262\u001b[0m       \u001b[1;32mreturn\u001b[0m \u001b[0msuper\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mVariableMetaclass\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcls\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m__call__\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\Continuum\\anaconda3\\envs\\env\\lib\\site-packages\\tensorflow_core\\python\\ops\\variables.py\u001b[0m in \u001b[0;36m_variable_v2_call\u001b[1;34m(cls, initial_value, trainable, validate_shape, caching_device, name, variable_def, dtype, import_scope, constraint, synchronization, aggregation, shape)\u001b[0m\n\u001b[0;32m    252\u001b[0m         \u001b[0msynchronization\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0msynchronization\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    253\u001b[0m         \u001b[0maggregation\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0maggregation\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 254\u001b[1;33m         shape=shape)\n\u001b[0m\u001b[0;32m    255\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    256\u001b[0m   \u001b[1;32mdef\u001b[0m \u001b[0m__call__\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mcls\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\Continuum\\anaconda3\\envs\\env\\lib\\site-packages\\tensorflow_core\\python\\ops\\variables.py\u001b[0m in \u001b[0;36m<lambda>\u001b[1;34m(**kws)\u001b[0m\n\u001b[0;32m    233\u001b[0m                         shape=None):\n\u001b[0;32m    234\u001b[0m     \u001b[1;34m\"\"\"Call on Variable class. Useful to force the signature.\"\"\"\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 235\u001b[1;33m     \u001b[0mprevious_getter\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;32mlambda\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkws\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mdefault_variable_creator_v2\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;32mNone\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkws\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    236\u001b[0m     \u001b[1;32mfor\u001b[0m \u001b[0m_\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mgetter\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mops\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget_default_graph\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_variable_creator_stack\u001b[0m\u001b[1;33m:\u001b[0m  \u001b[1;31m# pylint: disable=protected-access\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    237\u001b[0m       \u001b[0mprevious_getter\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0m_make_getter\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mgetter\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mprevious_getter\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\Continuum\\anaconda3\\envs\\env\\lib\\site-packages\\tensorflow_core\\python\\ops\\variable_scope.py\u001b[0m in \u001b[0;36mdefault_variable_creator_v2\u001b[1;34m(next_creator, **kwargs)\u001b[0m\n\u001b[0;32m   2554\u001b[0m       \u001b[0msynchronization\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0msynchronization\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2555\u001b[0m       \u001b[0maggregation\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0maggregation\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 2556\u001b[1;33m       shape=shape)\n\u001b[0m\u001b[0;32m   2557\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2558\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\Continuum\\anaconda3\\envs\\env\\lib\\site-packages\\tensorflow_core\\python\\ops\\variables.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(cls, *args, **kwargs)\u001b[0m\n\u001b[0;32m    260\u001b[0m       \u001b[1;32mreturn\u001b[0m \u001b[0mcls\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_variable_v2_call\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    261\u001b[0m     \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 262\u001b[1;33m       \u001b[1;32mreturn\u001b[0m \u001b[0msuper\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mVariableMetaclass\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcls\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m__call__\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    263\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    264\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\Continuum\\anaconda3\\envs\\env\\lib\\site-packages\\tensorflow_core\\python\\ops\\resource_variable_ops.py\u001b[0m in \u001b[0;36m__init__\u001b[1;34m(self, initial_value, trainable, collections, validate_shape, caching_device, name, dtype, variable_def, import_scope, constraint, distribute_strategy, synchronization, aggregation, shape)\u001b[0m\n\u001b[0;32m   1404\u001b[0m           \u001b[0maggregation\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0maggregation\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1405\u001b[0m           \u001b[0mshape\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mshape\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1406\u001b[1;33m           distribute_strategy=distribute_strategy)\n\u001b[0m\u001b[0;32m   1407\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1408\u001b[0m   def _init_from_args(self,\n",
      "\u001b[1;32m~\\AppData\\Local\\Continuum\\anaconda3\\envs\\env\\lib\\site-packages\\tensorflow_core\\python\\ops\\resource_variable_ops.py\u001b[0m in \u001b[0;36m_init_from_args\u001b[1;34m(self, initial_value, trainable, collections, caching_device, name, dtype, constraint, synchronization, aggregation, distribute_strategy, shape)\u001b[0m\n\u001b[0;32m   1487\u001b[0m     if isinstance(initial_value, ops.Tensor) and hasattr(\n\u001b[0;32m   1488\u001b[0m         initial_value, \"graph\") and initial_value.graph.building_function:\n\u001b[1;32m-> 1489\u001b[1;33m       raise ValueError(\"Tensor-typed variable initializers must either be \"\n\u001b[0m\u001b[0;32m   1490\u001b[0m                        \u001b[1;34m\"wrapped in an init_scope or callable \"\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1491\u001b[0m                        \u001b[1;34m\"(e.g., `tf.Variable(lambda : \"\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mValueError\u001b[0m: Tensor-typed variable initializers must either be wrapped in an init_scope or callable (e.g., `tf.Variable(lambda : tf.truncated_normal([10, 40]))`) when building functions. Please file a feature request if this restriction inconveniences you."
     ]
    }
   ],
   "source": [
    "epochs = [100,150,250,300]\n",
    "batch_size = [8, 16, 32, 64 ,128]\n",
    "learn_rate = [0.001, 0.0005, 0.0001, 0.0007, 0.0003]\n",
    "param_grid = dict(epochs=epochs,batch_size=batch_size,learn_rate=learn_rate)\n",
    "# create model\n",
    "inChannel = 3\n",
    "x, y = 128, 128\n",
    "input_img = Input(shape = (x, y, inChannel))\n",
    "model = KerasClassifier(build_fn=create_model, verbose=1)\n",
    "model = Model(input_img,create_model(input_img), verbose=1)\n",
    "model2 = Model(input_img, decoder(encoder2(input_img)))\n",
    "grid = GridSearchCV(estimator=model, param_grid=param_grid, n_jobs=-1, cv=3) # use all the cores (n_ jobs =-1), or set to 1 if err\n",
    "grid_result = grid.fit(X_train, X_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
